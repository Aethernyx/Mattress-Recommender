{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = '/Users/alex/Downloads/chromedriver 4'\n",
    "browser = webdriver.Chrome(chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://leesa.com'\n",
    "browser.get(url + '/mattresses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(browser.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/481 reviews added\n",
      "100/481 reviews added\n",
      "200/481 reviews added\n",
      "300/481 reviews added\n",
      "400/481 reviews added\n",
      "0/1150 reviews added\n",
      "100/1150 reviews added\n",
      "200/1150 reviews added\n",
      "300/1150 reviews added\n",
      "400/1150 reviews added\n",
      "500/1150 reviews added\n",
      "600/1150 reviews added\n",
      "700/1150 reviews added\n",
      "800/1150 reviews added\n",
      "900/1150 reviews added\n",
      "1000/1150 reviews added\n",
      "1100/1150 reviews added\n",
      "0/2505 reviews added\n",
      "100/2505 reviews added\n",
      "200/2505 reviews added\n",
      "300/2505 reviews added\n",
      "400/2505 reviews added\n",
      "500/2505 reviews added\n",
      "600/2505 reviews added\n",
      "700/2505 reviews added\n",
      "800/2505 reviews added\n",
      "900/2505 reviews added\n",
      "1000/2505 reviews added\n",
      "1100/2505 reviews added\n",
      "1200/2505 reviews added\n",
      "1300/2505 reviews added\n",
      "1400/2505 reviews added\n",
      "1500/2505 reviews added\n",
      "1600/2505 reviews added\n",
      "1700/2505 reviews added\n",
      "1800/2505 reviews added\n",
      "1900/2505 reviews added\n",
      "2000/2505 reviews added\n",
      "2100/2505 reviews added\n",
      "2200/2505 reviews added\n",
      "2300/2505 reviews added\n",
      "2400/2505 reviews added\n",
      "2500/2505 reviews added\n",
      "0/527 reviews added\n",
      "100/527 reviews added\n",
      "200/527 reviews added\n",
      "300/527 reviews added\n",
      "400/527 reviews added\n",
      "500/527 reviews added\n",
      "0/937 reviews added\n",
      "100/937 reviews added\n",
      "200/937 reviews added\n",
      "300/937 reviews added\n",
      "400/937 reviews added\n",
      "500/937 reviews added\n",
      "600/937 reviews added\n",
      "700/937 reviews added\n",
      "800/937 reviews added\n",
      "900/937 reviews added\n"
     ]
    }
   ],
   "source": [
    "brand, model, rating, review, warranty, trial, reviewer_name,\\\n",
    "review_location, review_date = get_reviews('tempur pedic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['brand'] = ['Tempur Pedic'] * len(df)\n",
    "df['model'] = model\n",
    "df['rating'] = rating\n",
    "df['review'] = review\n",
    "df['warranty'] = warranty\n",
    "df['trial'] = trial\n",
    "df['reviewer_name'] = reviewer_name\n",
    "df['review_location'] = review_location\n",
    "df['review_date'] = review_date\n",
    "\n",
    "df.to_csv('tempur_pedic_all_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>warranty</th>\n",
       "      <th>trial</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>review_location</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tempur Pedic</td>\n",
       "      <td>TEMPUR-Cloud</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Love love Tempur pedic, I always use this prod...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>90</td>\n",
       "      <td>Danny Wardana</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Dec 16, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tempur Pedic</td>\n",
       "      <td>TEMPUR-Cloud</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I recently began experiencing general body ach...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>90</td>\n",
       "      <td>Professional Sleeper</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Dec 6, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempur Pedic</td>\n",
       "      <td>TEMPUR-Cloud</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It's a pleasure sleeping on it. I only wish I ...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>90</td>\n",
       "      <td>Best sleep</td>\n",
       "      <td>L.I</td>\n",
       "      <td>Nov 28, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tempur Pedic</td>\n",
       "      <td>TEMPUR-Cloud</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We love our new mattress! It's night and day c...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>90</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Hagerstown</td>\n",
       "      <td>Nov 22, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempur Pedic</td>\n",
       "      <td>TEMPUR-Cloud</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Did not have to go shopping around...knew from...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>90</td>\n",
       "      <td>Rested!</td>\n",
       "      <td>St. Clair Shores</td>\n",
       "      <td>Nov 12, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>Tempur Pedic</td>\n",
       "      <td>TEMPUR-breeze</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I wake up every morning in more pain then the ...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>90</td>\n",
       "      <td>Bad sleep</td>\n",
       "      <td>Pampa</td>\n",
       "      <td>Jan 12, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>Tempur Pedic</td>\n",
       "      <td>TEMPUR-breeze</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wife and I decided to upgrade from a Queen to ...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>90</td>\n",
       "      <td>NO SLEEP Jason</td>\n",
       "      <td>Lafayette</td>\n",
       "      <td>Nov 28, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5597</th>\n",
       "      <td>Tempur Pedic</td>\n",
       "      <td>TEMPUR-breeze</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I bought this mattress because It was suppose ...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>90</td>\n",
       "      <td>Do not buy !!! This mattress is hot !!!</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Oct 5, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5598</th>\n",
       "      <td>Tempur Pedic</td>\n",
       "      <td>TEMPUR-breeze</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Might work if you sleep on your back but if yo...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>90</td>\n",
       "      <td>Eli</td>\n",
       "      <td>New York</td>\n",
       "      <td>Jun 28, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>Tempur Pedic</td>\n",
       "      <td>TEMPUR-breeze</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bought this mattress thinking it would be bett...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>90</td>\n",
       "      <td>Pain in Backs</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>May 27, 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5600 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand          model  rating  \\\n",
       "0     Tempur Pedic   TEMPUR-Cloud     5.0   \n",
       "1     Tempur Pedic   TEMPUR-Cloud     5.0   \n",
       "2     Tempur Pedic   TEMPUR-Cloud     5.0   \n",
       "3     Tempur Pedic   TEMPUR-Cloud     5.0   \n",
       "4     Tempur Pedic   TEMPUR-Cloud     5.0   \n",
       "...            ...            ...     ...   \n",
       "5595  Tempur Pedic  TEMPUR-breeze     1.0   \n",
       "5596  Tempur Pedic  TEMPUR-breeze     1.0   \n",
       "5597  Tempur Pedic  TEMPUR-breeze     1.0   \n",
       "5598  Tempur Pedic  TEMPUR-breeze     1.0   \n",
       "5599  Tempur Pedic  TEMPUR-breeze     1.0   \n",
       "\n",
       "                                                 review warranty  trial  \\\n",
       "0     Love love Tempur pedic, I always use this prod...  10-Year     90   \n",
       "1     I recently began experiencing general body ach...  10-Year     90   \n",
       "2     It's a pleasure sleeping on it. I only wish I ...  10-Year     90   \n",
       "3     We love our new mattress! It's night and day c...  10-Year     90   \n",
       "4     Did not have to go shopping around...knew from...  10-Year     90   \n",
       "...                                                 ...      ...    ...   \n",
       "5595  I wake up every morning in more pain then the ...  10-Year     90   \n",
       "5596  Wife and I decided to upgrade from a Queen to ...  10-Year     90   \n",
       "5597  I bought this mattress because It was suppose ...  10-Year     90   \n",
       "5598  Might work if you sleep on your back but if yo...  10-Year     90   \n",
       "5599  Bought this mattress thinking it would be bett...  10-Year     90   \n",
       "\n",
       "                                reviewer_name    review_location   review_date  \n",
       "0                               Danny Wardana         Birmingham  Dec 16, 2020  \n",
       "1                        Professional Sleeper            Atlanta   Dec 6, 2020  \n",
       "2                                  Best sleep                L.I  Nov 28, 2020  \n",
       "3                                         Amy         Hagerstown  Nov 22, 2020  \n",
       "4                                     Rested!   St. Clair Shores  Nov 12, 2020  \n",
       "...                                       ...                ...           ...  \n",
       "5595                                Bad sleep              Pampa  Jan 12, 2020  \n",
       "5596                           NO SLEEP Jason          Lafayette  Nov 28, 2019  \n",
       "5597  Do not buy !!! This mattress is hot !!!       New Orleans    Oct 5, 2019  \n",
       "5598                                      Eli           New York  Jun 28, 2019  \n",
       "5599                            Pain in Backs           Pasadena  May 27, 2019  \n",
       "\n",
       "[5600 rows x 9 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(company, number_of_reviews=0):\n",
    "    brand = []\n",
    "    model = []\n",
    "    rating = []\n",
    "    review = []\n",
    "    warranty = []\n",
    "    trial = []\n",
    "    reviewer_name = []\n",
    "    review_location = []\n",
    "    review_date = []\n",
    "    \n",
    "    #INSERT INTO Mattress_Info (brand, model, size, style, price)\n",
    "    #VALUES (brand, model, size, style, price)\n",
    "    \n",
    "    #INSERT INTO Reviews (brand, model, review, additional_info, name, location, review_date)\n",
    "    #VALUES (brand, model, review, additional_info)\n",
    "    \n",
    "    \n",
    "    if company.lower() == 'tempur pedic':\n",
    "        # tempur pedic url\n",
    "        url = 'https://www.tempurpedic.com/shop-mattresses/'\n",
    "        browser.get(url)\n",
    "        \n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        mattresses = soup.find_all(attrs={'aria-label': 'Mattress Model'})\n",
    "        \n",
    "        for i in range(len(mattresses)):\n",
    "            # Finding the link of the specific mattress on the page and redirecting to that page\n",
    "            browser.get(mattresses[i].find('a').get('href'))\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            \n",
    "            # getting all reviews\n",
    "            total_reviews = soup.find(attrs={'class': \n",
    "                                     'star-rating__review-number configurator__star-rating__review-number'}).text\n",
    "            total_reviews = int(re.sub(' Reviews', '', total_reviews))\n",
    "\n",
    "\n",
    "            time.sleep(5)\n",
    "            \n",
    "            #browser.find_element_by_xpath('//*[@id=\"reviews__body\"]/div[2]/div[1]/div[2]').click()\n",
    "            # Clicking the review sort by drop down menu below\n",
    "            element = browser.find_element_by_xpath('//*[@id=\"review-sort\"]')\n",
    "            browser.execute_script(\"arguments[0].click();\", element)\n",
    "            #browser.find_element_by_xpath('').click()\n",
    "            # Clicking on 'Newest' from the review sort by dropdown menu to sort by Newest Reviews\n",
    "            element = browser.find_element_by_xpath('//*[@id=\"review-sort\"]/option[3]')\n",
    "            browser.execute_script(\"arguments[0].click();\", element)\n",
    "            #browser.find_element_by_xpath('//*[@id=\"review-sort\"]/option[3]').click()\n",
    "\n",
    "            viewable_reviews = len(soup.find_all(attrs={'aria-label': 'Product Review'}))\n",
    "            count = 0\n",
    "            while count < total_reviews:\n",
    "                browser.maximize_window()\n",
    "                if viewable_reviews != total_reviews:\n",
    "                    try:\n",
    "                        browser.find_element_by_xpath('//*[@id=\"reviews__body\"]').click()\n",
    "                        page_data = browser.page_source\n",
    "                        soup = BeautifulSoup(page_data, 'html.parser')\n",
    "                        element = browser.find_element_by_xpath('//*[@id=\"reviews__body\"]/div[2]/div[2]/div[2]')\n",
    "                        browser.execute_script(\"arguments[0].click();\", element)\n",
    "                        viewable_reviews = len(soup.find_all(attrs={'aria-label': 'Product Review'}))\n",
    "                        count=viewable_reviews\n",
    "                    except NoSuchElementException:\n",
    "                        break\n",
    "\n",
    "            page_data = browser.page_source\n",
    "            soup = BeautifulSoup(page_data, 'html.parser')\n",
    "            for x in range(total_reviews):\n",
    "                brand.append('Tempur Pedic')\n",
    "                model.append(soup.find(class_='configurator__title').text[:-1])\n",
    "                warranty.append('10-Year')\n",
    "                trial.append(90)\n",
    "                rating.append(float(soup.find_all('div', attrs={'class':'star-rating__number product-reviews-filter__star-rating__number'})[x].text))\n",
    "                review.append(re.sub('[\\n\\t]', '', soup.find_all('div', attrs={'class': 'customer-review__review-item__copy'})[x].text))\n",
    "                reviewer_name.append(soup.find_all('div', attrs={'class': 'customer-review__review-item__review-author'})[x].text.split(',')[0])\n",
    "                review_location.append(soup.find_all('div', attrs={'class': 'customer-review__review-item__review-author'})[x].text.split(',')[1])\n",
    "                review_date.append(soup.find_all('div', attrs={'class': 'customer-review__review-item__date'})[x].text)\n",
    "\n",
    "                if x % 100 == 0:\n",
    "                    print(str(x) + '/' + str(total_reviews) + ' reviews added')\n",
    "                \n",
    "                \n",
    "    if company.lower() == 'casper':\n",
    "        url = 'https://casper.com'\n",
    "        browser.get(url + '/mattresses')\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        \n",
    "        # Gathering the spot on the page which contains links for all individual matresses\n",
    "        mattresses = soup.find_all('div', attrs={'class': 'sc-1fi10si-50 gzIyoR'})\n",
    "        \n",
    "        for mattress in range(len(mattresses)):\n",
    "            # Going to each individual page for each mattress\n",
    "            browser.get(url + mattresses[mattress].find('a').get('href'))\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            \n",
    "            # Getting the total review counts for each mattress on the mattress page\n",
    "            total_reviews = int(re.sub('\\W', '', soup.find_all(attrs={'data-qa': 'render-total-count'})[0].text))\n",
    "            count = 0\n",
    "            # Changing the total review count to 2000 if the amount of reviews is greater than 2000\n",
    "            if total_reviews > number_of_reviews:\n",
    "                total_reviews = number_of_reviews\n",
    "\n",
    "            trial_ = int(soup.find_all(class_='NavItemText-sc-15rw0ng-6 dMJZWe')[1].text[:3])\n",
    "            warranty_ = soup.find_all(class_='NavItemText-sc-15rw0ng-6 dMJZWe')[2].text[:7]\n",
    "            model_type = soup.find_all(attrs={'class': 'x900hc-3 dbmrVC'})[1].text + ' Mattress'\n",
    "\n",
    "            # Clicking to get to the page with full reviews\n",
    "            browser.find_element_by_link_text('See all reviews').click()\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            \n",
    "            # Changing the sorting method of reviews to most recent\n",
    "                # Clicking the sort by drop down menu\n",
    "            element = browser.find_element_by_xpath('//*[@id=\"reviews\"]/div[1]/div[2]/div/div/button/span[1]')\n",
    "            browser.execute_script(\"arguments[0].click();\", element)\n",
    "                # Clicking the Most Recent option in the sort by drop down menu\n",
    "            element = browser.find_element_by_xpath('//*[@id=\"reviews\"]/div[1]/div[2]/div/div/ul/li[2]/span')\n",
    "            browser.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "            while count < total_reviews:\n",
    "                soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "                count+=len(soup.find_all('div', attrs={'class':'rn6em9-0 innTNk'}))\n",
    "                for i in range(len(soup.find_all('div', attrs={'class':'rn6em9-0 innTNk'}))):\n",
    "                    brand.append('Casper')\n",
    "                    model.append(model_type)\n",
    "                    trial.append(trial_)\n",
    "                    warranty.append(warranty_)\n",
    "                    review.append(soup.find_all('div', attrs={'class':'rn6em9-0 innTNk'})[i].text)\n",
    "                    rating.append(int(soup.find_all(class_='lnmqqa-3 ncHUI')[i].text[0]))\n",
    "                    reviewer_name.append(re.match('\\w+', soup.find_all(class_='sc-55wbfa-1 hoZTLI')[i].text).group().replace('Checkmark', ''))\n",
    "                    if len(soup.find_all(class_='sc-55wbfa-0 bUotLN')) != 10:\n",
    "                        review_location.append(soup.find_all(class_='sc-55wbfa-2 dVruIH')[i].text.split('Owner')[1])\n",
    "                    elif len(soup.find_all(class_='sc-55wbfa-0 bUotLN')) == 10:   \n",
    "                        review_location.append(soup.find_all(class_='sc-55wbfa-0 bUotLN')[i].text)\n",
    "                    review_date.append(soup.find_all(class_='imungi-8 fmEyIG')[0].text.replace('Review left on ', ''))\n",
    "                if count % 100 == 0:\n",
    "                    print(str(count) + '/' + str(total_reviews) + ' reviews added')\n",
    "\n",
    "                element = browser.find_element_by_xpath('//*[@id=\"reviews\"]/div[2]/div[2]/a[3]')\n",
    "                browser.execute_script(\"arguments[0].click();\", element)\n",
    "                \n",
    "    if company.lower() == 'leesa':\n",
    "        url = 'https://www.leesa.com'\n",
    "        browser.get(url + '/pages/compare-mattresses')\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        \n",
    "        mattress_1 = '//*[@id=\"shopify-section-compare-page-header\"]/div[4]/div/div[1]/a'\n",
    "        mattress_2 = '//*[@id=\"shopify-section-compare-page-header\"]/div[4]/div/div[2]/a'\n",
    "        mattress_3 = '//*[@id=\"shopify-section-compare-page-header\"]/div[4]/div/div[3]/a'\n",
    "\n",
    "        for link in [mattress_1, mattress_2, mattress_3]:\n",
    "            browser.find_element_by_xpath(link).click()\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        \n",
    "            # Clicking to go to reviews\n",
    "            element = browser.find_element_by_xpath('//*[@id=\"edge-fix\"]/div/div/div[1]/div/div')\n",
    "            browser.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "            time.sleep(5)\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            try:\n",
    "                browser.find_element_by_xpath('//*[@id=\"privy-inner-container\"]/div[38]/div/div/div[2]/img').click()\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(5)\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            \n",
    "            try:\n",
    "                # Clicking drop down menu on reviews page to switch to recent\n",
    "                element = browser.find_element_by_xpath('//*[@id=\"bv-dropdown-title-reviews\"]')\n",
    "                browser.execute_script(\"arguments[0].click();\", element)\n",
    "                # Click most recent on drop down menu\n",
    "                time.sleep(5)\n",
    "                soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "                browser.find_element_by_xpath('//*[@id=\"data-bv-dropdown-item-mostRecent\"]').click()\n",
    "            except:\n",
    "                pass\n",
    "            # Clicking body of page if needed because of pop-up\n",
    "            #browser.find_element_by_xpath('//*[@id=\"privy-inner-container\"]/div[26]/div/div/div[2]/img').click()\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            total_reviews = int(soup.find(class_='bv-rating-label bv-text-link bv-focusable').text.split()[0])\n",
    "            \n",
    "            if total_reviews > number_of_reviews:\n",
    "                total_reviews = number_of_reviews\n",
    "            count = 0\n",
    "\n",
    "            while count < total_reviews:\n",
    "                soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "                count+= len(soup.find_all(class_='bv-rating bv-rating-stars bv-rating-stars-off'))\n",
    "\n",
    "                for i in range(len(soup.find_all(class_='bv-rating bv-rating-stars bv-rating-stars-off'))):\n",
    "                    brand.append('leesa')\n",
    "                    model.append(soup.find_all(attrs={'class': 'text__center color__green text__weight__semibold'})[0].text + ' Mattress')\n",
    "                    review.append(soup.find_all('div', attrs={'class': 'bv-content-summary-body-text'})[i].text)\n",
    "                    rating.append(int(soup.find_all(class_='bv-rating bv-rating-stars bv-rating-stars-off')[i]['title'][0]))\n",
    "                    reviewer_name.append(soup.find_all(attrs={'itemprop': 'author'})[i].text)\n",
    "                    warranty.append('10-Year')\n",
    "                    trial.append(100)\n",
    "                    review_location.append(soup.find_all(attrs={'class':'bv-author-location'})[i].text)\n",
    "                    review_date_current = soup.find_all('span', attrs={'class': 'bv-content-datetime-stamp'})[i].text[:-2]\n",
    "                    today = datetime.today()\n",
    "                    try:\n",
    "                        review_dt = int(review_date_current.split()[0])\n",
    "                    except:\n",
    "                        review_dt = 1\n",
    "                    if 'days' in review_date_current:\n",
    "                        review_dt = today - timedelta(days=review_dt)\n",
    "                        review_dt = review_dt.strftime('%m-%d-%y')\n",
    "                    elif 'month' in review_date_current:\n",
    "                        review_dt = today - relativedelta(months=review_dt)\n",
    "                        review_dt = review_dt.strftime('%m-%d-%y')\n",
    "                    elif 'year' in review_date_current:\n",
    "                        review_dt = today - relativedelta(years=review_dt)\n",
    "                        review_dt = review_dt.strftime('%m-%d-%y')\n",
    "\n",
    "                    review_date.append(review_dt)\n",
    "\n",
    "                browser.find_element_by_xpath('//*[@id=\"BVRRContainer\"]/div/div/div/div/div[3]/div/ul/li[2]/a/span[2]').click()\n",
    "                if count % 100 == 0:\n",
    "                    print('{0}/{1} reviews added'.format(count, total_reviews))\n",
    "            browser.get(url + '/pages/compare-mattresses')\n",
    "                \n",
    "    if company.lower() == 'purple':\n",
    "        url = 'https://purple.com'\n",
    "        browser.get(url + '/mattresses/')\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        time.sleep(5)\n",
    "        \n",
    "        for i in range(3):\n",
    "            mattress = soup.find_all('div', attrs={'class': 'product-info-container ta-left m-b-4'})[i].find('a').get('href')\n",
    "            browser.get(url+mattress)\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "            # Click dropdown menu\n",
    "            element = browser.find_element_by_xpath('//*[@id=\"stamped-sort-select\"]')\n",
    "            browser.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "            # Click most recent on drop down menu\n",
    "            element = browser.find_element_by_xpath('//*[@id=\"stamped-sort-select\"]/option[3]')\n",
    "            browser.execute_script(\"arguments[0].click();\", element)\n",
    "            time.sleep(5)\n",
    "\n",
    "            total_reviews = int(soup.find('li', attrs={'id': 'tab-reviews'}).get('data-count'))\n",
    "            if total_reviews > number_of_reviews:\n",
    "                total_reviews = number_of_reviews\n",
    "            count = 0\n",
    "\n",
    "            while count < total_reviews:\n",
    "                soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "                count+= len(soup.find_all(class_='stamped-starratings stamped-review-header-starratings'))\n",
    "                for i in range(len(soup.find_all(class_='stamped-starratings stamped-review-header-starratings'))):\n",
    "                    brand.append('purple')\n",
    "                    model.append(soup.find('h1', attrs={'class': 'fs-h-3'}).text)\n",
    "                    c = collections.Counter(soup.find_all(class_='stamped-starratings stamped-review-header-starratings')[i])\n",
    "                    c_2 = list(c)\n",
    "                    c_key = c_2[1]\n",
    "                    rating.append(collections.Counter(soup.find_all(class_='stamped-starratings stamped-review-header-starratings')[i])[c_key])\n",
    "                    review.append(soup.find_all(class_='stamped-review-content-body')[i].text)\n",
    "                    warranty.append('10-Year')\n",
    "                    trial.append(100)\n",
    "                    reviewer_name.append(soup.find_all('div', attrs={'class': 'author'})[i])\n",
    "                    review_location.append(soup.find_all('div', attrs={'class': 'review-location'})[i].text)\n",
    "                    review_date.append(soup.find_all('div', attrs={'class': 'created'})[i].text)\n",
    "\n",
    "                element = browser.find_element_by_xpath('//*[@id=\"stamped-main-widget\"]/div/div[3]/div[5]/ul/li[14]/a')\n",
    "                browser.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "            browser.get(url + '/mattresses/')\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    \n",
    "    if company.lower() == 'serta':\n",
    "        url = 'https://www.serta.com'\n",
    "        browser.get(url + '/mattresses')\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        mattress_links = soup.find_all('div', attrs={'class': 'ProductGrid'})[0].find_all('a')\n",
    "        \n",
    "        for i in range(len(mattress_links)):\n",
    "            browser.get(url + mattress_links[i].get('href'))\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            time.sleep(4)\n",
    "            try:\n",
    "                browser.find_element_by_xpath('//*[@id=\"hero\"]/div[2]/div[3]/div/div/form/div/div/div/button').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"hero\"]/div[2]/div[3]/div/div/form/div/div/div/ul/li[4]/button').click()\n",
    "                total_reviews = int(soup.find_all(class_='bv_numReviews_component_container')[0].text.split('(')[1].replace(')', ''))\n",
    "                if total_reviews > number_of_reviews:\n",
    "                    total_reviews = number_of_reviews\n",
    "                count = 0\n",
    "\n",
    "                while count < total_reviews:\n",
    "                    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "                    count += len(soup.find_all(class_='BVRRReviewTextParagraph BVRRReviewTextFirstParagraph BVRRReviewTextLastParagraph'))\n",
    "\n",
    "                    for i in range(len(soup.find_all(class_='BVRRReviewTextParagraph BVRRReviewTextFirstParagraph BVRRReviewTextLastParagraph'))):\n",
    "                        brand.append('serta')\n",
    "                        model.append(soup.find('h1', attrs={'class': 'pdp__product-heading'}).text)\n",
    "                        rating.append(int(soup.find_all('img', attrs={'src': 'https://serta.ugc.bazaarvoice.com/0245-en_us/5_0/9/rating.gif'})[i]['alt'][0]))\n",
    "                        review.append(soup.find_all(class_='BVRRReviewTextParagraph BVRRReviewTextFirstParagraph BVRRReviewTextLastParagraph')[i].text)\n",
    "                        warranty.append('10-Year')\n",
    "                        trial.append(120)\n",
    "                        reviewer_name.append(soup.find_all(class_='BVRRNickname')[i].text)\n",
    "                        if 'BVRRUserLocationContainer' in soup.find_all(class_='BVRRContextDataContainer')[i]['class']:\n",
    "                            review_location.append(re.search(':\\w+', \n",
    "                                             soup.find_all(class_='BVRRContextDataContainer')[i].text)\\\n",
    "                                   .group().split('A')[0].split(':')[1])\n",
    "                        else:\n",
    "                            review_location.append('')\n",
    "                        review_date.append(soup.find_all(class_='BVRRValue BVRRReviewDate')[i].text)\n",
    "\n",
    "                    browser.find_element_by_xpath('//*[@id=\"BVRRDisplayContentFooterID\"]/div/span[6]').click()\n",
    "                    if count % 10 == 0:\n",
    "                        print(str(count) + '/' + str(total_reviews) + ' reviews added')\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    if company.lower() == 'sealy':\n",
    "        url = 'https://www.sealy.com/online-mattresses/cocoon-sealy-chill/v/45/'\n",
    "        browser.get(url)\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        # Clicking to get to reviews\n",
    "        browser.find_element_by_xpath('//*[@id=\"product-detail\"]/div[1]/div/div/div/div[2]/button[2]').click()\n",
    "        # Clicking dropdown to sort by new\n",
    "        browser.find_element_by_xpath('//*[@id=\"review-sort\"]').click()\n",
    "        # Clicking new in the dropdown menue to sort by new\n",
    "        browser.find_element_by_xpath('//*[@id=\"review-sort\"]/option[3]').click()\n",
    "\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        total_reviews = int(soup.find('div', attrs={'class': 'customer-review__number'}).text.split('+')[0])\n",
    "        if total_reviews>2000:\n",
    "            total_reviews = 2000\n",
    "        count = 0\n",
    "\n",
    "        visible_reviews = len(soup.find_all('div', attrs={'class': 'customer-review__review-item__review-author'}))\n",
    "\n",
    "        while count < total_reviews:\n",
    "            if visible_reviews < total_reviews:\n",
    "                element = browser.find_element_by_xpath('//*[@id=\"reviews__body\"]/div[2]/div[2]/div[2]')\n",
    "                browser.execute_script(\"arguments[0].click();\", element)\n",
    "                soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "                visible_reviews = len(soup.find_all('div', attrs={'class': 'customer-review__review-item__review-author'}))\n",
    "\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')     \n",
    "            for i in range(len(soup.find_all('div', attrs={'class': 'customer-review__review-item__copy'}))):\n",
    "                brand.append('Sealy')\n",
    "                model.append(soup.find('h2', attrs={'class': 'configurator__title'}).text)\n",
    "                rating.append(soup.find_all('span', attrs={'class': 'ada-screenreader-only'})[i+9].text)\n",
    "                review.append(soup.find_all('div', attrs={'class': 'customer-review__review-item__copy'})[i].text)\n",
    "                warranty.append('10-Year')\n",
    "                trial.append(100)\n",
    "                reviewer_name.append(soup.find_all('div', attrs={'class': 'customer-review__review-item__review-author'})[i].text.split(',')[0])\n",
    "                review_location.append(','.join(soup.find_all('div', attrs={'class': 'customer-review__review-item__review-author'})[i].text.split(',')[1:]))\n",
    "                review_date.append(soup.find_all('div', attrs={'class': 'customer-review__review-item__date'})[0].text)\n",
    "                count += 1\n",
    "\n",
    "                if count % 100 == 0:\n",
    "                    print('{}/{} reviews added'.format(count, total_reviews))\n",
    "            \n",
    "            \n",
    "    return brand, model, rating, review, warranty, trial, reviewer_name, review_location, review_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['brand'] = brand\n",
    "df['model'] = model\n",
    "df['rating'] = rating\n",
    "df['review'] = review\n",
    "df['warranty'] = warranty\n",
    "df['trial'] = trial\n",
    "df['reviewer_name'] = reviewer_name\n",
    "df['review_location'] = review_location\n",
    "df['review_date'] = review_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Sealy_Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_2(company, number_of_reviews):\n",
    "    brand = []\n",
    "    price = []\n",
    "    rating = []\n",
    "    review = []\n",
    "    queen_size = []\n",
    "    warranty = []\n",
    "    trial = []\n",
    "    reviewer_name = []\n",
    "    review_location = []\n",
    "    review_date = []\n",
    "\n",
    "\n",
    "    url = 'https://purple.com/mattresses/purple-bed'\n",
    "    browser.get(url)\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Click dropdown menu\n",
    "    element = browser.find_element_by_xpath('//*[@id=\"stamped-sort-select\"]')\n",
    "    browser.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "    # Click most recent on drop down menu\n",
    "    element = browser.find_element_by_xpath('//*[@id=\"stamped-sort-select\"]/option[3]')\n",
    "    browser.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "    total_reviews = 500\n",
    "    count = 0\n",
    "\n",
    "    while count < total_reviews:\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        count+= len(soup.find_all(class_='stamped-starratings stamped-review-header-starratings'))\n",
    "        for i in range(len(soup.find_all(class_='stamped-starratings stamped-review-header-starratings'))):\n",
    "            brand.append('purple')\n",
    "            price.append(1049)\n",
    "            c = collections.Counter(soup.find_all(class_='stamped-starratings stamped-review-header-starratings')[i])\n",
    "            c_2 = list(c)\n",
    "            c_key = c_2[1]\n",
    "            rating.append(collections.Counter(soup.find_all(class_='stamped-starratings stamped-review-header-starratings')[i])[c_key])\n",
    "            review.append(soup.find_all(class_='stamped-review-content-body')[i].text)\n",
    "            queen_size.append('')\n",
    "            warranty.append('10-Year')\n",
    "            trial.append(100)\n",
    "            reviewer_name.append(soup.find_all('div', attrs={'class': 'author'})[i])\n",
    "            review_location.append(soup.find_all('div', attrs={'class': 'review-location'})[i].text)\n",
    "            review_date.append(soup.find_all('div', attrs={'class': 'created'})[i].text)\n",
    "\n",
    "        element = browser.find_element_by_xpath('//*[@id=\"stamped-main-widget\"]/div/div[3]/div[5]/ul/li[14]/a')\n",
    "        browser.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "    return brand, price, rating, review, queen_size, warranty, trial, reviewer_name, review_location, review_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AC Pacific: Reviews and info on Amazon\n",
    "\n",
    "Sealy: Sealy website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob('*.csv')\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv(file, lineterminator='\\n')\n",
    "    df_list.append(data)\n",
    "    \n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>warranty</th>\n",
       "      <th>trial</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>review_location</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>purple</td>\n",
       "      <td>The Purple Mattress</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I am a hard worker with way more to physically...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;div class=\"author\"&gt;Jessica G.&lt;/div&gt;</td>\n",
       "      <td>United States</td>\n",
       "      <td>02/22/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>purple</td>\n",
       "      <td>The Purple Mattress</td>\n",
       "      <td>5.0</td>\n",
       "      <td>First off I am a disabled veteran with insomni...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;div class=\"author\"&gt;Jared B.&lt;/div&gt;</td>\n",
       "      <td>Warrenton, Virginia</td>\n",
       "      <td>09/19/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>purple</td>\n",
       "      <td>The Purple Mattress</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This mattress is well made and the process of ...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;div class=\"author\"&gt;LeAnn M.&lt;/div&gt;</td>\n",
       "      <td>United States</td>\n",
       "      <td>03/05/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>purple</td>\n",
       "      <td>The Purple Mattress</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The regular twin foam mattress was marked as a...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;div class=\"author\"&gt;Kathryn W.&lt;/div&gt;</td>\n",
       "      <td>United States</td>\n",
       "      <td>03/04/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>purple</td>\n",
       "      <td>The Purple Mattress</td>\n",
       "      <td>4.0</td>\n",
       "      <td>We had a premium mattress for years (Sterns an...</td>\n",
       "      <td>10-Year</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;div class=\"author\"&gt;Adam R.&lt;/div&gt;</td>\n",
       "      <td>United States</td>\n",
       "      <td>03/04/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>5093</td>\n",
       "      <td>Casper</td>\n",
       "      <td>Element Mattress</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My granddaughter finds her new twin very comfo...</td>\n",
       "      <td>10-year</td>\n",
       "      <td>100</td>\n",
       "      <td>Tricia</td>\n",
       "      <td>Clermont, FL</td>\n",
       "      <td>Jul 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094</th>\n",
       "      <td>5094</td>\n",
       "      <td>Casper</td>\n",
       "      <td>Element Mattress</td>\n",
       "      <td>5.0</td>\n",
       "      <td>After years and years of sleeping on coils, my...</td>\n",
       "      <td>10-year</td>\n",
       "      <td>100</td>\n",
       "      <td>Jared</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Jul 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>5095</td>\n",
       "      <td>Casper</td>\n",
       "      <td>Element Mattress</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have had a hard time sleeping since I broke ...</td>\n",
       "      <td>10-year</td>\n",
       "      <td>100</td>\n",
       "      <td>Megan</td>\n",
       "      <td>LARAMIE, WY</td>\n",
       "      <td>Jul 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>5096</td>\n",
       "      <td>Casper</td>\n",
       "      <td>Element Mattress</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Firmer than I expected but best sleep ever. I ...</td>\n",
       "      <td>10-year</td>\n",
       "      <td>100</td>\n",
       "      <td>Joshua</td>\n",
       "      <td>Robinson, IL</td>\n",
       "      <td>Jul 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>5097</td>\n",
       "      <td>Casper</td>\n",
       "      <td>Element Mattress</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The Essential is a great mattress, especially ...</td>\n",
       "      <td>10-year</td>\n",
       "      <td>100</td>\n",
       "      <td>Lucia</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Jul 24, 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22997 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   brand                model  rating  \\\n",
       "0              0  purple  The Purple Mattress     5.0   \n",
       "1              1  purple  The Purple Mattress     5.0   \n",
       "2              2  purple  The Purple Mattress     1.0   \n",
       "3              3  purple  The Purple Mattress     3.0   \n",
       "4              4  purple  The Purple Mattress     4.0   \n",
       "...          ...     ...                  ...     ...   \n",
       "5093        5093  Casper     Element Mattress     5.0   \n",
       "5094        5094  Casper     Element Mattress     5.0   \n",
       "5095        5095  Casper     Element Mattress     5.0   \n",
       "5096        5096  Casper     Element Mattress     4.0   \n",
       "5097        5097  Casper     Element Mattress     5.0   \n",
       "\n",
       "                                                 review warranty  trial  \\\n",
       "0     I am a hard worker with way more to physically...  10-Year    100   \n",
       "1     First off I am a disabled veteran with insomni...  10-Year    100   \n",
       "2     This mattress is well made and the process of ...  10-Year    100   \n",
       "3     The regular twin foam mattress was marked as a...  10-Year    100   \n",
       "4     We had a premium mattress for years (Sterns an...  10-Year    100   \n",
       "...                                                 ...      ...    ...   \n",
       "5093  My granddaughter finds her new twin very comfo...  10-year    100   \n",
       "5094  After years and years of sleeping on coils, my...  10-year    100   \n",
       "5095  I have had a hard time sleeping since I broke ...  10-year    100   \n",
       "5096  Firmer than I expected but best sleep ever. I ...  10-year    100   \n",
       "5097  The Essential is a great mattress, especially ...  10-year    100   \n",
       "\n",
       "                             reviewer_name      review_location   review_date  \n",
       "0     <div class=\"author\">Jessica G.</div>        United States    02/22/2021  \n",
       "1       <div class=\"author\">Jared B.</div>  Warrenton, Virginia    09/19/2017  \n",
       "2       <div class=\"author\">LeAnn M.</div>        United States    03/05/2021  \n",
       "3     <div class=\"author\">Kathryn W.</div>        United States    03/04/2021  \n",
       "4        <div class=\"author\">Adam R.</div>        United States    03/04/2021  \n",
       "...                                    ...                  ...           ...  \n",
       "5093                                Tricia         Clermont, FL  Jul 24, 2018  \n",
       "5094                                 Jared      Los Angeles, CA  Jul 24, 2018  \n",
       "5095                                 Megan          LARAMIE, WY  Jul 24, 2018  \n",
       "5096                                Joshua         Robinson, IL  Jul 24, 2018  \n",
       "5097                                 Lucia         New York, NY  Jul 24, 2018  \n",
       "\n",
       "[22997 rows x 10 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
